# -- Additional labels to be applied to installed resources. Note that not all resources will receive these labels.
additionalLabels: {}

crds:
  # -- Whether to install the `HTTPScaledObject` [`CustomResourceDefinition`](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/)
  install: true

# operator-specific configuration values
operator:
  # -- The image pull secrets for the operator component
  imagePullSecrets: []
  # -- The namespace to watch for new `HTTPScaledObject`s. Leave this blank (i.e. `""`) to tell the operator to watch all namespaces.
  watchNamespace: ""
  # -- The image pull policy for the operator component
  pullPolicy: Always
  # operator pod resource limits
  resources:
    # -- The CPU/memory resource limit for the operator component
    limits:
      cpu: 0.5
      memory: 64Mi
    # -- The CPU/memory resource request for the operator component
    requests:
      cpu: 250m
      memory: 20Mi
  # -- The port for the operator main server to run on
  port: 8443
  # -- Node selector for pod scheduling ([docs](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/))
  nodeSelector: {}
  # -- Tolerations for pod scheduling ([docs](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/))
  tolerations: []
  # -- Affinity for pod scheduling ([docs](https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/))
  affinity: {}

scaler:
  # -- The image pull secrets for the scaler component
  imagePullSecrets: []
  # -- The name of the Kubernetes `Service` for the scaler component
  service: external-scaler
  # -- The image pull policy for the scaler component
  pullPolicy: Always
  # -- The port for the scaler's gRPC server. This is the server that KEDA will send scaling requests to.
  grpcPort: 9090
  # -- The port for the scaler's health check and admin server
  healthPort: 9091
  # -- The number of "target requests" that the external scaler will report to KEDA for the interceptor's scaling metrics. See the [KEDA external scaler documentation](https://keda.sh/docs/2.4/concepts/external-scalers/) for details on target requests.
  pendingRequestsInterceptor: 200
  # -- Interval in ms for communicating IsActive to KEDA
  streamInterval: 200
  # -- Node selector for pod scheduling ([docs](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/))
  nodeSelector: {}
  # -- Tolerations for pod scheduling ([docs](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/))
  tolerations: []
  # -- Affinity for pod scheduling ([docs](https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/))
  affinity: {}
  resources:
    limits:
      cpu: 0.5
      memory: 64Mi
    requests:
      cpu: 250m
      memory: 20Mi

interceptor:
  # -- The image pull secrets for the interceptor component
  imagePullSecrets: []
  # -- The image pull policy for the interceptor component
  pullPolicy: Always
  # configurable values for the interceptor's admin
  # service. the admin service is a cluster-internal
  # HTTP interface for triggering debugging behavior
  admin:
    # -- The name of the Kubernetes `Service` for the interceptor's admin service
    service: interceptor-admin
    # -- The port for the interceptor's admin server to run on
    port: 9090
  # configurable values for the interceptor's proxy
  # service. the proxy service is the publicly accessible
  # HTTP interface that production requests go to
  proxy:
    # -- The name of the Kubernetes `Service` for the interceptor's proxy service. This is the service that accepts live HTTP traffic.
    service: interceptor-proxy
    # -- The port on which the interceptor's proxy service will listen for live HTTP traffic
    port: 8080
  replicas:
    # -- The minimum number of interceptor replicas that should ever be running
    min: 3
    # -- The maximum number of interceptor replicas that should ever be running
    max: 50
    # -- The maximum time the interceptor should wait for an HTTP request to reach a backend before it is considered a failure
    waitTimeout: 20s

  # configuration for the ScaledObject resource for the
  # interceptor
  scaledObject:
    # -- The interval (in milliseconds) that KEDA should poll the external scaler to fetch scaling metrics about the interceptor
    pollingInterval: 1

  # -- How long the interceptor waits to establish TCP connections with backends before failing a request.
  tcpConnectTimeout: 500ms
  # -- The interceptor's connection keep alive timeout
  keepAlive: 1s
  # -- How long the interceptor will wait between forwarding a request to a backend and receiving response headers back before failing the request
  responseHeaderTimeout: 500ms
  # -- How often (in milliseconds) the interceptor does a full refresh of its deployment cache. The interceptor will also use Kubernetes events to stay up-to-date with the deployment cache changes. This duration is the maximum time it will take to see changes to the deployment state.
  deploymentCachePollingIntervalMS: 250
  # -- Whether or not the interceptor should force requests to use HTTP/2
  forceHTTP2: false
  # -- The maximum number of idle connections allowed in the interceptor's in-memory connection pool. Set to 0 to indicate no limit
  maxIdleConns: 100
  # -- The timeout after which any idle connection is closed and removed from the interceptor's in-memory connection pool.
  idleConnTimeout: 90s
  # -- The maximum amount of time the interceptor will wait for a TLS handshake. Set to zero to indicate no timeout.
  tlsHandshakeTimeout: 10s
  # -- Special handling for responses with "Expect: 100-continue" response headers. see https://pkg.go.dev/net/http#Transport under the 'ExpectContinueTimeout' field for more details
  expectContinueTimeout: 1s
  # -- Node selector for pod scheduling ([docs](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/))
  nodeSelector: {}
  # -- Tolerations for pod scheduling ([docs](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/))
  tolerations: []
  # -- Affinity for pod scheduling ([docs](https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/))
  affinity: {}
  # interceptor pod resource limits
  resources:
    # -- The CPU/memory resource limit for the operator component
    limits:
      cpu: 0.5
      memory: 64Mi
    # -- The CPU/memory resource request for the operator component
    requests:
      cpu: 250m
      memory: 20Mi

# configuration for the images to use for each component
images:
  # tag is the image tag to use for all images.
  # for example, if the operator image is "myoperator" and
  # tag is "mytag", the operator image used will be
  # "myoperator:mytag". `latest` is used to indicate the latest
  # stable release in the official images, `canary` is
  # the build for the latest commit to the `main` branch,
  # and you can target any other commit with `sha-<GIT_SHA[0:7]>`
  # -- Image tag for the http add on. This tag is applied to the images listed in `images.operator`, `images.interceptor`, and `images.scaler`. Optional, given app version of Helm chart is used by default
  tag: ""
  # -- Image name for the operator image component
  operator: ghcr.io/kedacore/http-add-on-operator
  # -- Image name for the interceptor image component
  interceptor: ghcr.io/kedacore/http-add-on-interceptor
  # -- Image name for the scaler image component
  scaler: ghcr.io/kedacore/http-add-on-scaler
  # the kube-rbac-proxy image to use
  kubeRbacProxy:
    # -- Image name for the Kube RBAC Proxy image component
    name: gcr.io/kubebuilder/kube-rbac-proxy
    # -- Image tag for the Kube RBAC Proxy image component
    tag: v0.13.0

rbac:
  # -- Install aggregate roles for edit and view
  aggregateToDefaultRoles: false
